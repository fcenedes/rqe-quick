# Redis RediSearch Performance Benchmark

**Schema-driven** Redis RediSearch benchmarking tool with beautiful CLI, realistic data generation, and comprehensive performance comparisons across multiple implementation approaches.

## ‚ú® Features

‚úÖ **Schema-Driven Architecture**
- **YAML Schema Definition**: Define your index structure in simple YAML files
- **Automatic Data Generation**: Realistic data using Faker and random generators
- **Multiple Storage Types**: Support for both HASH and JSON storage
- **All Field Types**: TAG, TEXT, NUMERIC, VECTOR, GEO fields
- **No Hardcoded Logic**: Everything driven by schema configuration

‚úÖ **Multiple Implementation Approaches**
- **Naive**: Sequential baseline implementation
- **Threaded**: Parallel workers with connection pooling using `ThreadPoolExecutor`
- **Async**: High-performance async/await with `uvloop` event loop

‚úÖ **Beautiful CLI Interface**
- Rich terminal output with tables and colors
- Schema visualization with field types and generators
- Animated progress bars with spinners
- Flexible command-line options
- Compare any combination of approaches

‚úÖ **Comprehensive Benchmarks**
- **Seeding**: Bulk document insertion with Redis pipelines
- **Top-K Aggregation**: Fast aggregation with `LIMIT` clause
- **Cursor Aggregation**: Memory-efficient pagination with `FT.CURSOR`

‚úÖ **Flexible Configuration**
- Environment-based configuration via `.env` file
- Support for local Redis, Redis Cloud, and Redis Cluster
- Username/password authentication support

‚úÖ **Production Ready**
- Modular architecture for easy maintenance
- Secure credential management
- Connection pooling with lazy initialization
- Proper resource cleanup
- Pydantic schema validation

---

## üìã Prerequisites

This project uses **[uv](https://github.com/astral-sh/uv)** for fast, reliable Python package management.

### Install uv (if not already installed)

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Or with pip
pip install uv
```

---

## üöÄ Quick Start

### 1. Install Dependencies

```bash
# Using uv (recommended - uses pyproject.toml)
uv sync

# Or using pip with requirements.txt
pip install -r requirements.txt
```

**Dependencies**:
- `redis>=5.0.0` - Redis client for Python
- `python-dotenv>=1.0.0` - Environment variable management
- `uvloop>=0.19.0` - Fast asyncio event loop
- `click>=8.1.0` - CLI framework
- `rich>=13.0.0` - Beautiful terminal output
- `pydantic>=2.0.0` - Schema validation
- `pyyaml>=6.0.0` - YAML parsing
- `faker>=20.0.0` - Realistic data generation

### 2. Configure Redis Connection

```bash
# Copy the sample configuration
cp .env.sample .env

# Edit with your settings
nano .env
```

**For local Redis** (default):
```bash
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_USERNAME=
REDIS_PASSWORD=
```

**For Redis Cloud**:
```bash
REDIS_HOST=your-redis-cloud-host.com
REDIS_PORT=11127
REDIS_USERNAME=default
REDIS_PASSWORD=your-password-here
```

### 3. Run Benchmark

```bash
# Run all benchmarks with default schema (ecommerce)
uv run python -m rqe.cli

# Quick test with fewer documents
uv run python -m rqe.cli -n 10000

# Use custom schema
uv run python -m rqe.cli -s schemas/user.yaml -n 5000
```

---

## üìê Schema Definition

### What is a Schema?

A schema defines your RediSearch index structure, field types, and data generators in a simple YAML file. This allows you to benchmark any index structure without writing code!

### Example Schema (E-commerce)

```yaml
version: '0.1.0'

index:
  name: ecommerce-idx
  prefix: 'product:'
  storage_type: 'hash'  # or 'json'

fields:
  - name: country
    type: tag
    generator: random.choice
    generator_args:
      choices: ["US", "FR", "DE", "IN", "BR", "CN", "GB", "ES", "IT", "JP"]

  - name: category
    type: tag
    generator: random.choice
    generator_args:
      choices: ["electronics", "books", "toys", "clothing", "grocery", "beauty", "sports"]

  - name: status
    type: tag
    generator: random.weighted_choice
    generator_args:
      choices: ["pending", "paid", "shipped", "delivered", "returned", "cancelled"]
      weights: [4, 10, 15, 25, 3, 2]

  - name: price
    type: numeric
    attrs:
      sortable: true
    generator: random.gauss
    generator_args:
      mu: 60.0
      sigma: 25.0
      min: 1.0
      max: 500.0

  - name: ts
    type: numeric
    attrs:
      sortable: true
    generator: random.timestamp
    generator_args:
      days_ago: 30

aggregations:
  - field: country
  - field: category
  - field: status
```

### Available Generators

**Random Generators:**
- `random.choice` - Random choice from list
- `random.weighted_choice` - Weighted random choice
- `random.randint` - Random integer in range
- `random.randfloat` - Random float in range
- `random.gauss` - Gaussian distribution
- `random.timestamp` - Random timestamps
- `random.bool` - Random boolean
- `random.uuid` - UUID-like strings

**Faker Generators:**
- `faker.name` - Full names
- `faker.email` - Email addresses
- `faker.user_name` - Usernames
- `faker.company` - Company names
- `faker.city` - City names
- `faker.country` - Country names
- `faker.country_code` - Country codes (US, FR, etc.)
- `faker.sentence` - Sentences with word count boundaries
- `faker.paragraph` - Paragraphs
- `faker.url` - URLs
- `faker.ipv4` - IPv4 addresses

**Vector Generators:**
- `vector.random_normalized` - L2-normalized vectors (for cosine similarity)
- `vector.random` - Uniform random vectors
- `vector.gaussian` - Gaussian-distributed vectors

### Field Types

- **TAG**: Exact-match searchable tags (indexed, not tokenized)
- **TEXT**: Full-text searchable text (tokenized, stemmed)
- **NUMERIC**: Numeric values (sortable, range queries)
- **VECTOR**: Vector embeddings (similarity search)
- **GEO**: Geographic coordinates (radius queries)

### Creating Custom Schemas

1. Copy an example schema:
```bash
cp schemas/ecommerce.yaml schemas/my-schema.yaml
```

2. Edit the schema:
```bash
nano schemas/my-schema.yaml
```

3. Run benchmark with your schema:
```bash
uv run python -m rqe.cli -s schemas/my-schema.yaml -n 10000
```

### Included Schemas

- **`schemas/ecommerce.yaml`**: E-commerce products (HASH storage, 5 fields)
- **`schemas/user.yaml`**: User profiles with vectors (JSON storage, 9 fields)

---

## üé® CLI Usage

### Basic Commands

```bash
# Show help and all available options
uv run python -m rqe.cli --help

# Run all benchmarks with default schema (ecommerce)
uv run python -m rqe.cli

# Run with custom schema
uv run python -m rqe.cli --schema schemas/user.yaml
uv run python -m rqe.cli -s schemas/my-schema.yaml

# Run specific approach
uv run python -m rqe.cli --approach naive
uv run python -m rqe.cli --approach threaded
uv run python -m rqe.cli --approach async

# Run multiple approaches (compare them) - repeat the flag
uv run python -m rqe.cli -a naive -a threaded
uv run python -m rqe.cli -a threaded -a async
uv run python -m rqe.cli --approach all  # All three approaches

# Run specific test
uv run python -m rqe.cli --test seeding
uv run python -m rqe.cli --test topk
uv run python -m rqe.cli --test cursor

# Run multiple tests - repeat the flag
uv run python -m rqe.cli -t seeding -t topk
uv run python -m rqe.cli --test all  # All three tests

# Combine options
uv run python -m rqe.cli -s schemas/user.yaml -a threaded -a async -t seeding
uv run python -m rqe.cli -a async -t topk -t cursor -n 50000

# Custom document count
uv run python -m rqe.cli --docs 50000
uv run python -m rqe.cli -n 100000

# Quiet mode (minimal output, CSV-like)
uv run python -m rqe.cli --quiet
uv run python -m rqe.cli -q

# Verbose mode (show aggregation details and validation)
uv run python -m rqe.cli --verbose
uv run python -m rqe.cli -v

# Recreate index (drop existing data) - use with caution!
uv run python -m rqe.cli --recreate
uv run python -m rqe.cli -r
```

### Short Options

| Short | Long | Description |
|-------|------|-------------|
| `-s` | `--schema` | Path to schema YAML file |
| `-a` | `--approach` | Implementation approach(es) to benchmark |
| `-t` | `--test` | Test type(s) to run |
| `-n` | `--docs` | Number of documents to seed |
| `-q` | `--quiet` | Quiet mode (minimal output) |
| `-v` | `--verbose` | Verbose mode (show aggregation details) |
| `-r` | `--recreate` | Recreate index (drop existing data) |

### Examples

```bash
# Compare threaded vs async for seeding with user schema
uv run python -m rqe.cli -s schemas/user.yaml -a threaded -a async -t seeding -n 50000

# Quick test with 1000 docs (default ecommerce schema)
uv run python -m rqe.cli -n 1000

# Full benchmark with all approaches and tests
uv run python -m rqe.cli -a all -t all

# Test async performance on cursor aggregation with custom schema
uv run python -m rqe.cli -s schemas/my-schema.yaml -a async -t cursor

# Compare all approaches on Top-K aggregation
uv run python -m rqe.cli -a all -t topk -n 100000

# Quiet mode for scripting/logging
uv run python -m rqe.cli -q > benchmark_results.txt

# Seed data once, then run multiple aggregation tests (data preserved by default)
uv run python -m rqe.cli -a async -t seeding -n 100000
uv run python -m rqe.cli -a async -t topk -v         # Data preserved, verbose output
uv run python -m rqe.cli -a async -t cursor -v       # Data preserved, verbose output

# Force recreate index (drops all data)
uv run python -m rqe.cli -a async -t seeding -n 100000 -r
```

---

## üìä Understanding the Output

### Configuration Display

```
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Setting              ‚îÇ Value                                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Redis Host           ‚îÇ redis-11127.c48004.eu-west9-mz.gcp.cloud.rlrcp.com ‚îÇ
‚îÇ Redis Port           ‚îÇ 11127                                              ‚îÇ
‚îÇ Redis DB             ‚îÇ 0                                                  ‚îÇ
‚îÇ Redis Username       ‚îÇ default                                            ‚îÇ
‚îÇ Redis Password       ‚îÇ ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè                                           ‚îÇ
‚îÇ Parallel Workers     ‚îÇ 8                                                  ‚îÇ
‚îÇ Connection Pool Size ‚îÇ 12                                                 ‚îÇ
‚îÇ Seed Batch Size      ‚îÇ 2,000                                              ‚îÇ
‚îÇ Aggregate Batch Size ‚îÇ 2,000                                              ‚îÇ
‚îÇ uvloop               ‚îÇ ‚úì Available                                        ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

### Schema Display

```
üìã Schema
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Property           ‚îÇ Value                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Index Name         ‚îÇ ecommerce-idx             ‚îÇ
‚îÇ Prefix             ‚îÇ product:                  ‚îÇ
‚îÇ Storage Type       ‚îÇ HASH                      ‚îÇ
‚îÇ Fields             ‚îÇ 5                         ‚îÇ
‚îÇ Aggregation Fields ‚îÇ country, category, status ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

üîß Fields
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ Name     ‚îÇ Type    ‚îÇ Generator              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ country  ‚îÇ TAG     ‚îÇ random.choice          ‚îÇ
‚îÇ category ‚îÇ TAG     ‚îÇ random.choice          ‚îÇ
‚îÇ status   ‚îÇ TAG     ‚îÇ random.weighted_choice ‚îÇ
‚îÇ price    ‚îÇ NUMERIC ‚îÇ random.gauss           ‚îÇ
‚îÇ ts       ‚îÇ NUMERIC ‚îÇ random.timestamp       ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

### Progress Bars

```
‚†ã Seeding (naive)... ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0:00:05
```

### Benchmark Results

```
üìä Benchmark Results
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Test       ‚îÉ Naive     ‚îÉ Threaded  ‚îÉ Async     ‚îÉ Best      ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Seeding    ‚îÇ 100.00s   ‚îÇ 94.34s    ‚îÇ 74.23s    ‚îÇ üèÜ Async  ‚îÇ
‚îÇ Top-K      ‚îÇ 2.450s    ‚îÇ 2.812s    ‚îÇ 2.130s    ‚îÇ üèÜ Async  ‚îÇ
‚îÇ Cursor     ‚îÇ 8.920s    ‚îÇ 8.415s    ‚îÇ 6.980s    ‚îÇ üèÜ Async  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ö° Speedup vs Naive
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Test       ‚îÉ Threaded  ‚îÉ Async     ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ Seeding    ‚îÇ 1.06x     ‚îÇ 1.35x     ‚îÇ
‚îÇ Top-K      ‚îÇ 0.87x     ‚îÇ 1.15x     ‚îÇ
‚îÇ Cursor     ‚îÇ 1.06x     ‚îÇ 1.28x     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Interpretation**:
- **Naive**: Baseline sequential implementation
- **Threaded**: Uses `ThreadPoolExecutor` with connection pool
- **Async**: Uses `asyncio` with `uvloop` for maximum performance
- **Best**: Highlighted with üèÜ trophy emoji
- **Speedup**: Shows how much faster compared to naive baseline

---

## ‚öôÔ∏è Configuration

All configuration is managed via the `.env` file:

### Redis Connection

| Variable | Description | Default |
|----------|-------------|---------|
| `REDIS_HOST` | Redis server hostname | `localhost` |
| `REDIS_PORT` | Redis server port | `6379` |
| `REDIS_DB` | Redis database number | `0` |
| `REDIS_USERNAME` | Redis username (empty for no auth) | _(empty)_ |
| `REDIS_PASSWORD` | Redis password (empty for no auth) | _(empty)_ |

### Performance Settings

| Variable | Description | Default | Recommended |
|----------|-------------|---------|-------------|
| `PARALLEL_WORKERS` | Number of concurrent workers | `4` | `2` for local, `4` for remote |
| `CONNECTION_POOL_SIZE` | Size of connection pool | `4` | Match `PARALLEL_WORKERS` |
| `SEED_BATCH_SIZE` | Pipeline batch size for seeding | `20000` | `50000` for local, `30000` for remote |
| `AGGREGATE_BATCH_SIZE` | Cursor batch size for aggregation | `20000` | `50000` for local, `30000` for remote |

### Data Generation Settings

| Variable | Description | Default | Notes |
|----------|-------------|---------|-------|
| `RANDOM_SEED` | Random seed for data generation | `42` | Same seed = same data (reproducible benchmarks). Change to generate different data. |

**Why RANDOM_SEED matters:**
- **Reproducibility**: Same seed generates identical data across runs
- **Consistency**: Compare performance changes without data variance
- **Testing**: Verify index behavior with known data patterns
- **Different Data**: Change seed (e.g., `43`, `100`, `999`) to test with different distributions

---

## üéØ Performance Tuning

### Understanding Batch Size vs Network MTU

**Key Insight**: Each HSET command for the ecommerce schema is ~210 bytes.

**Network Layer**:
- MTU (Ethernet): 1,500 bytes
- TCP payload: 1,460 bytes (after IP/TCP headers)
- Commands per packet: ~6 (1,260 bytes)

**Batch Size Impact**:
| Batch Size | Total Bytes | TCP Packets | Efficiency | Memory |
|------------|-------------|-------------|------------|--------|
| 1,000 | 210 KB | 144 | 97.2% | ~0.2 MB |
| 2,000 | 420 KB | 288 | 97.2% | ~0.4 MB |
| 5,000 | 1.05 MB | 720 | 97.2% | ~1.0 MB |
| 10,000 | 2.1 MB | 1,439 | 97.3% | ~2.0 MB |

**Recommendation**: Batch sizes above 1,000 achieve >97% TCP efficiency. Choose based on latency tolerance and memory.

---

### For Single Redis Instance (Local)

```bash
# .env
PARALLEL_WORKERS=2
CONNECTION_POOL_SIZE=2
SEED_BATCH_SIZE=50000
AGGREGATE_BATCH_SIZE=50000
```

**Why?**
- Redis is single-threaded, so parallelism has minimal benefit
- Real performance gain comes from larger batch sizes
- Local latency is <1ms, so large batches don't hurt

**Expected Results**:
- Async: 20-30% faster than threaded
- Threaded: 5-10% faster than naive
- Batch size increase: 5-10x speedup

---

### For Redis Cloud (Remote) - **YOUR SETUP**

```bash
# .env
PARALLEL_WORKERS=4
CONNECTION_POOL_SIZE=4
SEED_BATCH_SIZE=10000
AGGREGATE_BATCH_SIZE=5000
```

**Why?**
- Network latency: 10-50ms (vs <1ms local)
- Larger batches hide latency better
- 10K batch = 2.1 MB = good balance
- 97.3% TCP efficiency
- Parallel connections help with remote Redis

**Current vs Recommended**:
- Current: `SEED_BATCH_SIZE=2000` (420 KB, 288 packets)
- Recommended: `SEED_BATCH_SIZE=10000` (2.1 MB, 1,439 packets)
- **5x larger batches = better latency hiding**

**Expected Results**:
- Async: 30-50% faster than threaded
- Threaded: 10-20% faster than naive
- Network latency hiding is key

---

### For Redis Cluster (Multiple Shards)

```bash
# .env
PARALLEL_WORKERS=8
CONNECTION_POOL_SIZE=8
SEED_BATCH_SIZE=20000
AGGREGATE_BATCH_SIZE=20000
```

**Why?**
- Parallelism actually helps with multiple Redis instances/shards!
- Each worker can target different shards
- True parallel execution

**Expected Results**:
- Async: 2-3x faster than threaded
- Threaded: Linear speedup with shard count
- True parallelism across shards

---

## üìÅ Project Structure

```
rqe-quick/
‚îú‚îÄ‚îÄ pyproject.toml             # Project metadata and dependencies (uv)
‚îú‚îÄ‚îÄ uv.lock                    # Locked dependencies (uv)
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies (pip fallback)
‚îÇ
‚îú‚îÄ‚îÄ .env                       # Your configuration (NOT committed)
‚îú‚îÄ‚îÄ .env.sample                # Configuration template (committed)
‚îú‚îÄ‚îÄ .gitignore                 # Protects .env from being committed
‚îÇ
‚îú‚îÄ‚îÄ README.md                  # This file
‚îú‚îÄ‚îÄ CLAUDE.md                  # Notes for Claude AI assistant
‚îÇ
‚îú‚îÄ‚îÄ schemas/                   # Schema definitions
‚îÇ   ‚îú‚îÄ‚îÄ ecommerce.yaml         # E-commerce products schema (default)
‚îÇ   ‚îî‚îÄ‚îÄ user.yaml              # User profiles schema (with vectors)
‚îÇ
‚îî‚îÄ‚îÄ rqe/                       # Main package
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ config.py              # Configuration management
    ‚îú‚îÄ‚îÄ connection.py          # RedisConnectionPool class
    ‚îú‚îÄ‚îÄ helpers.py             # Shared helper functions
    ‚îú‚îÄ‚îÄ index.py               # Schema-driven index management
    ‚îú‚îÄ‚îÄ benchmark.py           # Schema-driven benchmark runner
    ‚îú‚îÄ‚îÄ cli.py                 # CLI interface with Rich
    ‚îÇ
    ‚îú‚îÄ‚îÄ schema/                # Schema infrastructure
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ models.py          # Pydantic schema models
    ‚îÇ   ‚îî‚îÄ‚îÄ loader.py          # YAML schema loader
    ‚îÇ
    ‚îú‚îÄ‚îÄ generators/            # Data generators
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ base.py            # Base generator class
    ‚îÇ   ‚îú‚îÄ‚îÄ random_gen.py      # Random-based generators
    ‚îÇ   ‚îú‚îÄ‚îÄ faker_gen.py       # Faker-based generators
    ‚îÇ   ‚îú‚îÄ‚îÄ vector_gen.py      # Vector generators
    ‚îÇ   ‚îî‚îÄ‚îÄ registry.py        # Generator factory
    ‚îÇ
    ‚îú‚îÄ‚îÄ seeding/               # Schema-driven seeding
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îî‚îÄ‚îÄ schema_based.py    # Naive/threaded/async seeding
    ‚îÇ
    ‚îî‚îÄ‚îÄ aggregation/           # Aggregation implementations
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ naive.py           # Sequential aggregation
        ‚îú‚îÄ‚îÄ threaded.py        # Parallel aggregation with threads
        ‚îî‚îÄ‚îÄ async_impl.py      # Async aggregation with uvloop
```

---

## üîç Implementation Approaches Explained

### 1. Naive (Sequential)

**How it works**:
- Single-threaded, sequential execution
- One operation at a time
- Simple and straightforward

**When to use**:
- Baseline for comparison
- Small datasets (< 10,000 documents)
- Debugging and testing

**Performance**: Slowest, but most predictable

### 2. Threaded (Parallel with ThreadPoolExecutor)

**How it works**:
- Uses `ThreadPoolExecutor` for parallel execution
- Connection pool with round-robin assignment
- Multiple workers process batches concurrently

**When to use**:
- Medium to large datasets (10,000 - 1,000,000 documents)
- Remote Redis instances (network latency)
- When you need predictable resource usage

**Performance**:
- Single Redis: 5-10% faster than naive
- Redis Cloud: 10-20% faster than naive
- Redis Cluster: Linear speedup with shard count

### 3. Async (Asyncio with uvloop)

**How it works**:
- Uses `asyncio` with `uvloop` event loop
- Non-blocking I/O with async/await
- Single-threaded but highly concurrent

**When to use**:
- Large datasets (> 100,000 documents)
- Remote Redis instances (best for network I/O)
- Maximum performance requirements

**Performance**:
- Single Redis: 20-30% faster than threaded
- Redis Cloud: 30-50% faster than threaded
- Redis Cluster: 2-3x faster than threaded

**Why uvloop?**
- Written in Cython (C extension)
- 2-4x faster than standard asyncio
- Drop-in replacement for asyncio event loop

---

## üß™ Test Types Explained

### 1. Seeding

**What it does**: Bulk inserts documents into Redis using pipelines

**Metrics**:
- Documents per second
- Total time to insert N documents
- Memory usage during insertion

**Use case**: Testing write performance and pipeline efficiency

### 2. Top-K Aggregation

**What it does**: Runs `FT.AGGREGATE` with `GROUPBY` and `LIMIT` clause

**Metrics**:
- Query execution time
- Number of groups returned
- Aggregation throughput

**Use case**: Testing fast aggregation for small result sets (e.g., top 100 countries)

### 3. Cursor Aggregation

**What it does**: Runs `FT.AGGREGATE` with `FT.CURSOR` for pagination

**Metrics**:
- Total time to read all results
- Cursor read operations
- Memory efficiency

**Use case**: Testing memory-efficient aggregation for large result sets

---

## üí° Advanced Usage

### Programmatic Usage

```python
from rqe.benchmark import BenchmarkRunner
from rqe.schema import load_schema

# Load schema
schema = load_schema("schemas/ecommerce.yaml")

# Create benchmark runner
runner = BenchmarkRunner(
    schema=schema,
    n_docs=100_000
)

# Setup index
runner.setup_index(recreate=True)

# Run seeding benchmark
result = runner.run_seeding(approach="async")
print(f"Seeding took {result.elapsed_time:.2f}s")

# Run aggregation benchmark
result = runner.run_aggregation(test_type="topk", approach="async")
print(f"Top-K aggregation took {result.elapsed_time:.2f}s")

# Cleanup
runner.cleanup()
```

### Creating Schemas Programmatically

```python
from rqe.schema import BenchmarkSchema, IndexSchema, FieldSchema

# Create schema programmatically
schema = BenchmarkSchema(
    version="0.1.0",
    index=IndexSchema(
        name="my-idx",
        prefix="doc:",
        storage_type="hash"
    ),
    fields=[
        FieldSchema(
            name="category",
            type="tag",
            generator="random.choice",
            generator_args={"choices": ["A", "B", "C"]}
        ),
        FieldSchema(
            name="score",
            type="numeric",
            generator="random.randint",
            generator_args={"min": 0, "max": 100}
        )
    ],
    aggregations=[
        {"field": "category"}
    ]
)

# Use in benchmark
runner = BenchmarkRunner(schema=schema, n_docs=10000)
```

### Custom Configuration

```python
from rqe.config import Config
import redis

# Override configuration
Config.PARALLEL_WORKERS = 8
Config.SEED_BATCH_SIZE = 50000

# Create Redis client with custom config
r = redis.Redis(**Config.get_redis_params())
```

### Connection Pool Usage

```python
from rqe.connection import RedisConnectionPool
from rqe.config import Config

# Create connection pool
pool = RedisConnectionPool(
    host=Config.REDIS_HOST,
    port=Config.REDIS_PORT,
    db=Config.REDIS_DB,
    username=Config.REDIS_USERNAME,
    password=Config.REDIS_PASSWORD,
    pool_size=4
)

# Get connection for worker
r = pool.get_connection(worker_id=0)

# Use connection
r.ping()

# Cleanup
pool.close_all()
```

---

## üîí Security

### Credential Management

‚úÖ **DO**:
- Use `.env` file for credentials (already in `.gitignore`)
- Use environment variables in production
- Use secrets management (AWS Secrets Manager, HashiCorp Vault, etc.)
- Restrict `.env` file permissions: `chmod 600 .env`

‚ùå **DON'T**:
- Commit `.env` to git (protected by `.gitignore`)
- Hardcode credentials in code
- Share `.env` files directly
- Log passwords or sensitive data

### Password Masking

The CLI automatically masks passwords in output:
```
Redis Password       ‚îÇ ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
```

---

## üêõ Troubleshooting

### "ModuleNotFoundError: No module named 'dotenv'"

```bash
# Using uv (recommended)
uv sync

# Or using pip
pip install python-dotenv
```

### "ModuleNotFoundError: No module named 'click'" or "No module named 'rich'"

```bash
# Install new dependencies
uv sync

# Or using pip
pip install click rich
```

### "Connection refused"

Check your Redis connection settings in `.env`:
```bash
# Verify your settings
cat .env

# Test connection
python -c "from rqe.config import Config; print(f'{Config.REDIS_HOST}:{Config.REDIS_PORT}')"
```

### "Authentication failed"

Verify username and password in `.env`:
```bash
REDIS_USERNAME=default
REDIS_PASSWORD=your-actual-password
```

### Performance not improving with threaded/async

For single Redis instance, focus on batch size, not parallelism:
```bash
# .env
PARALLEL_WORKERS=2
SEED_BATCH_SIZE=50000
AGGREGATE_BATCH_SIZE=50000
```

Redis is single-threaded, so batch size matters more than parallelism.

### "uvloop not available" warning

Install uvloop for maximum async performance:
```bash
uv sync
# or
pip install uvloop
```

The async implementation will fall back to standard asyncio if uvloop is not available, but performance will be lower.

---

## üìà Benchmarking Best Practices

### 1. Warm-up Runs

Run benchmarks multiple times and discard the first run:
```bash
# First run (warm-up)
python main.py -n 10000

# Second run (actual benchmark)
python main.py -n 100000
```

### 2. Consistent Environment

- Close other applications
- Use consistent Redis configuration
- Run on same hardware/network
- Disable CPU throttling

### 3. Multiple Iterations

```bash
# Run 5 times and average results
for i in {1..5}; do
  python main.py -q >> results.txt
done
```

### 4. Document Count Selection

- **Quick test**: 1,000 - 10,000 documents
- **Standard test**: 100,000 - 200,000 documents
- **Stress test**: 1,000,000+ documents

---

## ü§ù Contributing

Contributions welcome! Please ensure:
- Code follows existing structure
- Configuration stays in `.env` file
- No credentials in code
- Documentation is updated
- Tests pass (if applicable)

---

## üìÑ License

This project is provided as-is for benchmarking and testing purposes.

---

## üÜò Support

For issues or questions:

1. **Check the README**: Most common issues are covered here
2. **Verify `.env` file**: Ensure configuration is correct
3. **Test connection**: `python -c "from rqe.config import Config; print(Config.REDIS_HOST)"`
4. **Run with verbose output**: `python main.py` (without `--quiet`)
5. **Check Redis logs**: Verify Redis is running and accessible

---

## üéØ Quick Reference

### Common Commands

```bash
# Full benchmark with default schema (all approaches, all tests)
uv run python -m rqe.cli

# Quick test with custom schema
uv run python -m rqe.cli -s schemas/user.yaml -n 10000

# Compare specific approaches (repeat the flag for multiple)
uv run python -m rqe.cli -a threaded -a async

# Run specific tests (repeat the flag for multiple)
uv run python -m rqe.cli -t topk -t cursor

# Combine multiple approaches and tests
uv run python -m rqe.cli -a threaded -a async -t topk -t cursor

# Test seeding only with custom schema
uv run python -m rqe.cli -s schemas/my-schema.yaml -t seeding

# Quiet mode for logging
uv run python -m rqe.cli -q > results.txt

# Help
uv run python -m rqe.cli --help
```

### CLI Options

| Option | Short | Values | Default | Description |
|--------|-------|--------|---------|-------------|
| `--schema` | `-s` | Path to YAML | `schemas/ecommerce.yaml` | Schema file to use |
| `--approach` | `-a` | `naive`, `threaded`, `async`, `all` | `all` | Approach(es) to benchmark |
| `--test` | `-t` | `seeding`, `topk`, `cursor`, `all` | `all` | Test(s) to run |
| `--docs` | `-n` | Integer | `500000` | Number of documents to seed |
| `--quiet` | `-q` | Flag | `false` | Quiet mode (CSV output) |
| `--verbose` | `-v` | Flag | `false` | Verbose mode (show aggregation details) |
| `--recreate` | `-r` | Flag | `false` | Recreate index (drop existing data) |

**Important**: For multiple values, **repeat the flag**:
```bash
# ‚úÖ CORRECT
-a threaded -a async -t topk -t cursor

# ‚ùå WRONG (doesn't work)
-a threaded,async -t topk,cursor
```

### Performance Expectations

| Setup | Naive | Threaded | Async |
|-------|-------|----------|-------|
| **Local Redis** | Baseline | +5-10% | +20-30% |
| **Redis Cloud** | Baseline | +10-20% | +30-50% |
| **Redis Cluster** | Baseline | +Linear | +2-3x |

### Configuration Quick Reference

```bash
# Local Redis (optimize for batch size)
PARALLEL_WORKERS=2
SEED_BATCH_SIZE=50000

# Redis Cloud (balance parallelism and batch size)
PARALLEL_WORKERS=4
SEED_BATCH_SIZE=30000

# Redis Cluster (maximize parallelism)
PARALLEL_WORKERS=8
SEED_BATCH_SIZE=20000
```

---

**Happy Benchmarking! üöÄ**


